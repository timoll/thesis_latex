\chapter{Model}
\label{chap:Model}

A very important step in hardware and software development is testing. For an eye tracking system it requires a big effort to do this with real data. The reason for that is the information where the participant looks at each moment needs to be recorded alongside of the video streams. For this project real time data processing is needed as there is no hardware available on Gazelle Compute to encode or store the video streams of the cameras.

A simple way of generating new data where the gaze direction and the camera positions are known would simplify the process of optimising the algorithm. 
\section{3D-Modeling Software}
\label{sec:whatIsImportant}

The 3D-Modeling software to create the model needs to fulfill a few requirements:
\begin{itemize}
	\item Correct representation of refracting light
	\item Create animations 
	\item \gls{API} that allows scripting
	\begin{itemize}
		\item Set position and rotation of certain objects at a certain frame
		\item Set camera properties and which camera is active
		\item Read the position and rotation of objects at any frame
	\end{itemize}
	\item (optional)Be free
	\item (optional)Run on Linux
	\begin{itemize}
		\item Server that can be used to render runs Linux containers
	\end{itemize}
	\item (optional)Be easy to learn
\end{itemize}

Blender is able to match all requirements although the last one might be debatable. You can apply a material property to a surface. This includes refracting. Rotation and position of objects can be inserted as key frames and it interpolates the steps in-between. 

Blender is also an open source project that is built with Python and has a powerful \gls{API} that gives access to nearly everything.
\section{Requirements for the Model}
In order to create a flexible model that is close to the reality, the model needs to follow the following requirements:
\begin{itemize}
	\item Correctly represent a human eye
	\item Accommodate for different eye parameters
	\begin{itemize}
		\item Eye diameter
		\item Distance between Eyes
	\end{itemize}
	\item Correctly represent camera placement and rotation
	\item Correctly represent camera properties
	\begin{itemize}
		\item Resolution
		\item Frame rate
		\item Field of View
	\end{itemize}
	\item Gaze direction can be animated
	\item Classes rotation and position can be animated
	\item Front facing cameras records gaze direction
\end{itemize}

\section{Human Eye}
A side view of a human eye model is visible in \ref{fig:humanEyeModel}. The camera can only see the front part of the eye. As a result only the cornea, anterior chamber and the iris need to be modelled correctly. The lens can be simplified by a black surface. 

It might be counter intuitive that the cornea extends as much out of the eyeball as visible in \ref{fig:humanEyeModel}. An easy way to verify that is to close the eye and move the eyes while holding a finger on the eyelid.
\label{sec:theHumanEye}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{images/human_eye_model.png}
	\caption{Side view of a human eye model \cite{gross:opticalSystems}}
	\label{fig:humanEyeModel}
\end{figure}

There are a few models with different values for the refracting indexes, radii and distances but they vary very little. So the simplified Gullstrand eye was chosen for the model.

\begin{table}[!htb]
\centering
\begin{tabular}{@{}|l|l|l|l|l|l|l|@{}}
	\hline
	\multirow{2}{*}{} & \multicolumn{3}{l|}{\thead{Relaxed}} & \multicolumn{3}{l|}{\thead{Accomodated}} \\ \hhline{~------}
	\thead{ Notaton\\{}} &  \thead{Radius r \\ {}[mm] }        & \thead{Thickness d\\ {}[mm]}    & \thead{Index n\\ {}}        & \thead{Radius r \\ {}[mm] }& \thead{Thickness d \\ {}[mm] }& \thead{Index n\\{} }    \\ \hline
	cornea     &  7.70        & 0.50      & 1.376       &  7.70   &0.50  & 1.376\\ \hline
	anterior chamber & 6.80        & 3.10     & 1.336       & 6.80    & 2.70&1.336 \\ \hline
	crystalline lens     &  10.0    & 3.60          & 1.4085    & 5.33   &   4.0  &  1.426 \\ \hline
	vitreous humor    p  & -6.00      & 17.187         & 1.336    & -5.33  & 13.816  &  1.336  \\ \hline
\end{tabular}
\caption{Properties of the eye with the simplified Gullstrand eye. \cite{gross:opticalSystems}}
\label{tab:gullstrandEye}
\end{table}

A human eye has on average a diameter of 24mm and the distance between the eyes ranges from 56mm to 72mm with the mean for men at 65mm and 62.6mm for women. \cite{gross:opticalSystems}
\section{Base Model}
\label{sec:theModel}

While there are quite a few parameters that need to be adjusted, some will remain the same. This can be incorporated into a base model that can then be adjusted by a script for each render.

This base model is centred around an accurate eye model that is built with the properties mentioned in section \ref{sec:theHumanEye}. Every eye is a group that can be manipulated with a script as one object. This includes a directed light cone that points where the eye is looking.

An existing model of the glasses is used and placed to approximately represent the position on a human head. Cameras are placed into the their cutouts in the glasses. The rotation is approximated to capture an average positioned eye correctly. The light cones that represent the gaze direction illuminate a small portion of a wall, which is captured by the front facing camera and is visible in figure \ref{fig:base3D}. Similar to the eye, the cameras and the glasses build a single object that can be moved and rotated. The result can be seen in figure \ref{fig:baseModel}
\begin{figure}
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{images/base_model_front.png}
		\caption{Front view of base model}
		\label{fig:baseFront}
	\end{subfigure}
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.787\linewidth]{images/base_model_side.png}
		\caption{Side view of base model}
		\label{fig:baseSide}
	\end{subfigure}
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{images/base_model_bottom.png}
		\caption{Bottom view of base model}
		\label{fig:baseBottom}
	\end{subfigure}
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{images/base_model_3D.png}
		\caption{3D-view of base model that shows also the light cone that follows the eye rotation}
		\label{fig:base3D}
	\end{subfigure}
	\caption{Finished base model with eyes in the center. A Script will place the eye correctly and generate an animation from the model that is shown here.}
	\label{fig:baseModel}
\end{figure}
\section{Scripting}
The base model alone is not enough to create meaningful results. Because there is no animation, the eyes are not placed and Blender would just render one camera. Additionally, the position and rotation of the eye and glasses needs to be logged for every frame. Otherwise, they can't be compared with the final gaze direction results. A simple way of configuring the script is needed to allow a wide variety of animations to be created.
\subsubsection{Automate Animation}
The script is written in Python because Blender offers a powerful Python \gls{API} that allows a script to modify every property in a model.
\gls{JSON} is a simple data-interchange format that is easy to read and write for humans. Sites such as \url{http://jsoneditoronline.org/} offer a convenient way to modify \gls{JSON}. The script uses a \gls{JSON} file with all the properties as input. It adjusts the values in the model and saves a modified blend file for each camera. This blend file is ready to be rendered without any further modification. The properties include static parameters such as the eye position and diameter. But also dynamic information for key frames such as the rotation of the eye and position of the glasses.
\subsubsection{Automate Process}
Even with the script, the process to generate render output is still very time consuming. First the script needs to be applied to base model, which produces the blend files that are ready to render. For each file a render job needs to be started. 

A Makefile offers a convenient way to automate the stages further. Additionally, it makes it simple to clean the whole mess up once the generated or rendered files are not needed anymore. 
With the Makefile the whole process is shorter and easier to remember:
\textbf{}
\begin{lstlisting}
#export config file
export ANIMATION_JSON=animation.json
make
make render
\end{lstlisting}

After a few hours test data is ready to be used for analysis.



